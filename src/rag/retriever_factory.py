# src/rag/retriever_factory.py
import os
from pathlib import Path
from typing import List

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.tools import tool, BaseTool
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter

from src.config import settings


class RAGRetrieverFactory:
    """
    RAG æ£€ç´¢å™¨å·¥åŽ‚ç±» (å•ä¾‹æ¨¡å¼)
    æ”¯æŒåŠ è½½æœ¬åœ°é¢„æž„å»ºçš„å‘é‡åº“ï¼Œæå‡å¯åŠ¨é€Ÿåº¦ã€‚
    """

    def __init__(
        self,
        knowledge_base_path: Path = settings.KNOWLEDGE_BASE_PATH,
        vector_store_path: Path = settings.VECTOR_STORE_PATH,
        embedding_model_name: str = settings.EMBEDDING_MODEL_NAME,
        chunk_size: int = settings.CHUNK_SIZE,
        chunk_overlap: int = settings.CHUNK_OVERLAP,
        search_k: int = settings.SEARCH_K,
    ):
        print("ðŸ”„ æ­£åœ¨åˆå§‹åŒ– RAG æœåŠ¡...")
        self.config = {
            "kb_path": knowledge_base_path,
            "vs_path": vector_store_path,
            "embedding": embedding_model_name,
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap,
            "search_k": search_k,
        }

        # 1. åˆå§‹åŒ– Embedding (å¿…é¡»ï¼Œæ— è®ºæ˜¯åŠ è½½è¿˜æ˜¯æž„å»ºéƒ½éœ€è¦)
        self.embeddings = HuggingFaceEmbeddings(model_name=self.config["embedding"])

        # 2. èŽ·å–å‘é‡åº“ (ä¼˜å…ˆåŠ è½½æœ¬åœ°)
        self.vectorstore = self._get_vectorstore()

        # 3. åˆ›å»ºæ£€ç´¢å™¨
        self.retriever = self.vectorstore.as_retriever(
            search_kwargs={"k": self.config["search_k"]}
        )
        print("âœ… RAG æ£€ç´¢å™¨å‡†å¤‡å°±ç»ªã€‚")

    def _get_vectorstore(self) -> FAISS:
        """
        èŽ·å–å‘é‡åº“å®žä¾‹ï¼š
        1. å°è¯•ä»Žæœ¬åœ°ç£ç›˜åŠ è½½ (é€Ÿåº¦å¿«)ã€‚
        2. å¦‚æžœæœ¬åœ°ä¸å­˜åœ¨ï¼Œåˆ™å›žé€€åˆ°ä»Žæºæ–‡ä»¶å†…å­˜æž„å»º (é€Ÿåº¦æ…¢)ã€‚
        """
        vs_path = self.config["vs_path"]

        # ç­–ç•¥ A: å°è¯•åŠ è½½æœ¬åœ°ç´¢å¼•
        if vs_path.exists() and (vs_path / "index.faiss").exists():
            try:
                print(f"ðŸ“‚ å‘çŽ°æœ¬åœ°å‘é‡åº“ï¼Œæ­£åœ¨åŠ è½½: {vs_path}")
                return FAISS.load_local(
                    str(vs_path),
                    self.embeddings,
                    # âœ… å¿…é¡»è®¾ç½®ä¸º True ä»¥å…è®¸åŠ è½½æœ¬åœ° pickle æ–‡ä»¶ (å®‰å…¨ä¿¡ä»»æœ¬åœ°æ–‡ä»¶)
                    allow_dangerous_deserialization=True,
                )
            except Exception as e:
                print(f"âš ï¸ åŠ è½½æœ¬åœ°å‘é‡åº“å¤±è´¥ ({e})ï¼Œå°†å›žé€€åˆ°é‡æ–°æž„å»º...")

        # ç­–ç•¥ B: å›žé€€åˆ°å†…å­˜æž„å»º
        print("ðŸ”¨ æœ¬åœ°ç´¢å¼•ä¸å¯ç”¨ï¼Œæ­£åœ¨ä»Žæºæ–‡ä»¶æž„å»ºå‘é‡åº“...")
        return self._build_from_source()

    def _build_from_source(self) -> FAISS:
        """ä»ŽåŽŸå§‹æ–‡æœ¬æž„å»ºå‘é‡åº“ (è€—æ—¶æ“ä½œ)"""
        file_path = self.config["kb_path"]

        if not file_path.exists():
            print(f"âš ï¸ ä¸¥é‡è­¦å‘Š: çŸ¥è¯†åº“æºæ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
            # è¿”å›žç©ºåº“é˜²æ­¢æŠ¥é”™
            empty_doc = Document(
                page_content="æš‚æ— çŸ¥è¯†åº“æ•°æ®ã€‚", metadata={"source": "empty"}
            )
            return FAISS.from_documents([empty_doc], self.embeddings)

        # åŠ è½½ä¸Žåˆ‡åˆ†
        loader = TextLoader(str(file_path), encoding="utf-8")
        documents = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config["chunk_size"],
            chunk_overlap=self.config["chunk_overlap"],
        )
        docs = text_splitter.split_documents(documents)

        # æž„å»ºç´¢å¼•
        return FAISS.from_documents(docs, self.embeddings)

    def retrieve(self, query: str) -> str:
        """æ ¸å¿ƒæ£€ç´¢é€»è¾‘"""
        try:
            docs = self.retriever.invoke(query)
            if not docs:
                return "æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            return "\n\n".join(doc.page_content for doc in docs)
        except Exception as e:
            return f"æ£€ç´¢çŸ¥è¯†åº“æ—¶å‘ç”Ÿé”™è¯¯: {e}"


# --- æ¨¡å—çº§å•ä¾‹ ---
rag_retriever_factory = RAGRetrieverFactory()


@tool
def search_port_regulations(query: str) -> str:
    """
    æŸ¥è¯¢å®æ³¢å£å²¸çš„æµ·å…³æŸ¥éªŒæµç¨‹ã€H98æŒ‡ä»¤å«ä¹‰ã€äººå·¥æŸ¥éªŒæ—¶æ•ˆåŠåº”å¯¹ç­–ç•¥ç­‰æ³•è§„çŸ¥è¯†ã€‚
    å½“é‡åˆ°ä¸æ¸…æ¥šçš„æŸ¥éªŒçŠ¶æ€ï¼ˆå¦‚H98ï¼‰æˆ–éœ€è¦åº”å¯¹å»ºè®®æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚
    """
    return rag_retriever_factory.retrieve(query)


def get_rag_tool() -> BaseTool:
    return search_port_regulations
